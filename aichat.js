const OpenAI = require("openai");
const fs = require("fs-extra");
const path = require("path");
const moment = require("moment-timezone");

module.exports.config = {
  name: "ai-chat",
  version: "1.0.0",
  hasPermssion: 0,
  credits: "Nnam (based on OpenAI/Gemini code)",
  description: "Chat v·ªõi AI (GPT-4o-mini), h·ªó tr·ª£ simulate fine-tune",
  commandCategory: "AI",
  usages: "ai-chat <prompt> | ai-chat fine-tune <data> [model: gpt-4o-mini]",
  cooldowns: 10 // Tr√°nh spam API
};

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || "sk-proj-your-key-here", // D√πng env var cho an to√†n
});

const fineTuneDataPath = path.join(__dirname, "ai_finetune_data.json");
if (!fs.existsSync(fineTuneDataPath)) fs.writeFileSync(fineTuneDataPath, JSON.stringify({}, null, 2));

function loadFineTuneData(userID) {
    const allData = JSON.parse(fs.readFileSync(fineTuneDataPath, 'utf8'));
    return allData[userID] || { prompts: [], model: "gpt-4o-mini" };
}

function saveFineTuneData(userID, data) {
    const allData = JSON.parse(fs.readFileSync(fineTuneDataPath, 'utf8'));
    allData[userID] = data;
    fs.writeFileSync(fineTuneDataPath, JSON.stringify(allData, null, 2));
}

module.exports.run = async function ({ api, event, args }) {
  const { threadID, messageID, senderID } = event;
  const cmd = args[0]?.toLowerCase();
  const prompt = args.slice(1).join(" ");
  const model = args[args.length - 1] || "gpt-4o-mini";

  if (!prompt) {
    return api.sendMessage(
      `ü§ñ [ AI-CHAT - GPT-4o-MINI ]\n\n` +
      `S·ª≠ d·ª•ng: ai-chat <prompt>\n` +
      `V√≠ d·ª•: ai-chat write a haiku about ai\n` +
      `ai-chat fine-tune "user: hello | ai: hi" gpt-4o-mini\n\n` +
      `‚ö†Ô∏è Gi·ªõi h·∫°n 100 token/prompt. Set OPENAI_API_KEY env var.`,
      threadID, messageID
    );
  }

  if (prompt.length > 200) return api.sendMessage("Prompt qu√° d√†i (>200 k√Ω t·ª±)!", threadID, messageID);

  try {
    if (cmd === "fine-tune") {
      // Simulate fine-tune: L∆∞u data nh∆∞ training file
      const userData = loadFineTuneData(senderID);
      userData.prompts.push({ user: prompt.split("|")[0], ai: prompt.split("|")[1] || "Default response" });
      userData.model = model;
      saveFineTuneData(senderID, userData);

      // "Train" by appending to system prompt
      const trainingPrompt = userData.prompts.map(p => `User: ${p.user}\nAI: ${p.ai}`).join("\n");
      const response = await openai.chat.completions.create({
        model: userData.model,
        messages: [
          { role: "system", content: `You are fine-tuned on: ${trainingPrompt}` },
          { role: "user", content: "Summarize your training data." }
        ],
      });

      return api.sendMessage(
        `‚úÖ Fine-tune simulate th√†nh c√¥ng!\n` +
        `üìö Data l∆∞u: ${userData.prompts.length} pairs\n` +
        `üìù Model: ${userData.model}\n` +
        `üí° Summary: ${response.choices[0].message.content.substring(0, 100)}...`,
        threadID, messageID
      );
    } else {
      // Normal chat
      const response = await openai.chat.completions.create({
        model: model,
        messages: [
          { role: "user", content: prompt }
        ],
        max_tokens: 100, // Gi·ªõi h·∫°n ƒë·ªÉ ti·∫øt ki·ªám
      });

      const aiResponse = response.choices[0].message.content;
      return api.sendMessage(
        `ü§ñ AI Response:\n"${aiResponse}"\n\n` +
        `üìä Model: ${model} | Tokens: ${response.usage.total_tokens}\n` +
        `üí° Prompt g·ªëc: "${prompt}"`,
        threadID, messageID
      );
    }
  } catch (error) {
    console.error("[AI-CHAT] L·ªói:", error);
    return api.sendMessage(`‚ùå L·ªói AI: ${error.message}. Ki·ªÉm tra API key!`, threadID, messageID);
  }
};
